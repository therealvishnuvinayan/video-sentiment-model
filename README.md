# ğŸ¤– Train and Deploy a Multimodal AI Model (2025)
### PyTorch Â· AWS Â· SageMaker Â· Next.js 15 Â· React Â· TailwindCSS

This project demonstrates how to **train, deploy, and integrate a multimodal AI model** using **PyTorch**, **AWS SageMaker**, and **Next.js 15**.  
The AI model processes **video, audio, and text inputs** to predict **emotion and sentiment**, and the trained model is deployed as an **API SaaS** application with a full web dashboard.

---

## ğŸš€ Overview

In this project, youâ€™ll:
1. Train a multimodal AI model combining **text, video, and audio encoders**.
2. Implement **multimodal fusion** for sentiment & emotion classification.
3. Deploy the trained model using **AWS SageMaker Endpoints**.
4. Build a **SaaS dashboard** using **Next.js 15**, **React**, **TailwindCSS**, and **Auth.js**.
5. Manage **user authentication**, **API key access**, and **quota tracking**.
6. Visualize **real-time inference** and analysis results.

---

## ğŸ§  Features

- ğŸ¥ **Video sentiment analysis**
- ğŸ§© **Multimodal fusion** of text, audio, and visual signals
- ğŸ™ï¸ **Audio feature extraction**
- ğŸ“ **Text embeddings** using **BERT**
- ğŸ“Š **Emotion and sentiment classification**
- âš™ï¸ **Model training, evaluation, and logging via TensorBoard**
- â˜ï¸ **AWS S3** for video storage  
- ğŸ¤– **SageMaker Endpoint** deployment for scalable inference  
- ğŸ” **Auth.js authentication**
- ğŸ”‘ **API key & usage quota management**
- ğŸ“ˆ **Interactive dashboard** with real-time inference
- ğŸ¨ **Modern UI built with Tailwind CSS**
- ğŸ’¾ **Database schema for users and usage tracking**
- ğŸŒ **End-to-end integration from training to SaaS product**

---

## ğŸ§° Tech Stack

### ğŸ§  Machine Learning
- **PyTorch** â€” Model training and multimodal fusion  
- **TensorBoard** â€” Logging and performance visualization  
- **MELD Dataset** â€” For emotion and sentiment labels  
- **FFmpeg** â€” Video and audio preprocessing  

### â˜ï¸ Cloud & Deployment
- **AWS S3** â€” Dataset and model storage  
- **AWS EC2** â€” Dataset preparation and instance management  
- **AWS SageMaker** â€” Training jobs and endpoint hosting  
- **IAM Roles** â€” Access control and API permissions  

### ğŸ’» Web Application
- **Next.js 15** â€” Frontend framework  
- **React.js** â€” Component-based UI  
- **Tailwind CSS** â€” Styling  
- **Auth.js** â€” Authentication  
- **Prisma / PostgreSQL** â€” Database and ORM  
- **T3 Stack** â€” Full-stack foundation for the SaaS layer  

---

## ğŸ§ª Dataset

**MELD (Multimodal EmotionLines Dataset)**  
A benchmark dataset for multimodal emotion recognition in conversations.  
ğŸ”— [MELD Official Website](https://affective-meld.github.io/)

The model extracts:
- **Text features** via BERT  
- **Audio embeddings** via spectral analysis  
- **Visual features** via CNN encoders  
Then fuses them for **emotion classification** (`happy`, `sad`, `neutral`, `angry`, etc.)

---

## ğŸ“¦ Folder Structure

```text
.
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ train.py               # Training script (PyTorch)
â”‚   â”œâ”€â”€ model.py               # Multimodal fusion model
â”‚   â”œâ”€â”€ dataset.py             # Custom dataset loader for MELD
â”‚   â””â”€â”€ inference.py           # Local inference
â”œâ”€â”€ aws/
â”‚   â”œâ”€â”€ s3_upload.py           # Upload dataset/model to S3
â”‚   â”œâ”€â”€ sagemaker_train.py     # Training job creation
â”‚   â”œâ”€â”€ sagemaker_deploy.py    # Endpoint deployment
â”‚   â””â”€â”€ invoke_endpoint.py     # Inference through API
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ app/                   # Next.js App Router
â”‚   â”œâ”€â”€ components/            # UI components
â”‚   â”œâ”€â”€ pages/api/             # API routes (Auth, Quotas, Inference)
â”‚   â””â”€â”€ styles/                # Tailwind styles
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### ğŸ”§ Local Development
```bash
git clone https://github.com/yourusername/multimodal-ai-saas.git
cd multimodal-ai-saas
```

#### 1ï¸âƒ£ Model Environment
```bash
cd model
pip install -r requirements.txt
python train.py
```

#### 2ï¸âƒ£ AWS Configuration
```bash
aws configure
python aws/s3_upload.py
python aws/sagemaker_train.py
python aws/sagemaker_deploy.py
```

#### 3ï¸âƒ£ SaaS Dashboard
```bash
cd web
npm install
npm run dev
```
Then open **http://localhost:3000**

---

## ğŸ’² AWS Cost Overview

| Service | Cost Estimate | Notes |
|----------|----------------|-------|
| SageMaker Training | ~15 USD | One-time full training job |
| Endpoint Hosting | ~1.5 USD/hour | Pay per uptime hour |
| S3 Storage | Very low | Based on dataset/model size |
| IAM Roles, Users | Free | Used for permission setup |

ğŸ’¡ **Free-tier workaround:**  
- Skip dataset upload & EC2 â€” use provided model from Google Drive.  
- Use dummy data for the API demo (as shown in the tutorial).  
- Try AWS free-tier instances for experimentation.

---

## ğŸ§© Example Features Implemented
- Multimodal encoder fusion (text + audio + video)
- Real-time inference dashboard
- Authenticated API request system
- API key creation & quota tracking
- Deployment automation using SageMaker SDK

---

## ğŸ“š References

- [PyTorch Documentation](https://pytorch.org/docs/)
- [AWS SageMaker Developer Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/)
- [Next.js Docs](https://nextjs.org/docs)
- [Auth.js](https://authjs.dev/)
- [Tailwind CSS](https://tailwindcss.com/)
- [Framer Motion](https://www.framer.com/motion/)

---

## ğŸ“œ License
This project is open-sourced under the **MIT License**.  
Feel free to fork, modify, or contribute responsibly.

---

Â© 2025 **Vishnu Vinayan**  
Built with â¤ï¸ using **PyTorch**, **AWS**, and **Next.js 15**
